{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "648e61f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, HalvingGridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import set_config\n",
    "set_config(enable_metadata_routing=True)\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from time import monotonic\n",
    "\n",
    "from utils.data_processing import load_data, transform_ipinfo, transform_datetime, transform_proxyinfo, df_ua_parser, transform_packetinfo, full_dtypes, raw_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5940b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 124\n",
    "data_path = Path(\"./data\")\n",
    "if data_path.joinpath(\"first_ml_processing.csv\").exists():\n",
    "    processed_data = pd.read_csv(data_path.joinpath(\"first_ml_processing.csv\"))\n",
    "    raw_data = pd.read_csv(data_path.joinpath(\"cybersecurity_attacks.csv\"))\n",
    "    \n",
    "    ip_cols = [\"Int Source IP\", \"Int Destination IP\", \"Global Source IP\", \"Global Destination IP\"]\n",
    "    raw_data[ip_cols] = transform_ipinfo(raw_data[[\"Source IP Address\", \"Destination IP Address\"]])\n",
    "else:\n",
    "    # Must use clean_data function to load data \n",
    "    dtypes = {col: col_type for col, col_type in full_dtypes.items() if col in raw_columns}\n",
    "    raw_data = load_data(data_path.joinpath(\"cybersecurity_attacks.csv\"), dtype=dtypes)\n",
    "\n",
    "    datetime_cols = [\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\", \"Second\", \"DayOfWeek\", \"IsWeekend\"]\n",
    "    raw_data[datetime_cols] = transform_datetime(raw_data[\"Timestamp\"])\n",
    "    device_cols = [\"String\",\"Browser Name\", \"Browser Version\", \"Browser Minor\", \"Browser Patch\",\n",
    "                    \"Browser Patch Minor\", \"OS Name\", \"OS Version\", \"OS Version Minor\",\n",
    "                    \"OS Version Patch\", \"OS Version Patch Minor\", \"Device Brand\", \"Device Model\",\n",
    "                    \"Device Type\"]\n",
    "    raw_data[device_cols] = df_ua_parser(raw_data[\"Device Information\"])\n",
    "    proxy_cols = [\"Is Proxy\"]\n",
    "    raw_data[proxy_cols] = transform_proxyinfo(raw_data[\"Proxy Information\"])\n",
    "    ip_cols = [\"Int Source IP\", \"Int Destination IP\", \"Global Source IP\", \"Global Destination IP\"]\n",
    "    raw_data[ip_cols] = transform_ipinfo(raw_data[[\"Source IP Address\", \"Destination IP Address\"]])\n",
    "    packet_cols = [\"Packet Bin\"]\n",
    "    raw_data[packet_cols] = transform_packetinfo(raw_data[\"Packet Length\"], scale=False)\n",
    "\n",
    "    processed_data = raw_data.drop(columns=[\"Payload Data\",\"Timestamp\", \"String\", \"Device Information\",\n",
    "                                    \"Proxy Information\", \"Source IP Address\", \"Destination IP Address\"])\n",
    "    processed_data.to_csv(data_path.joinpath(\"first_ml_processing.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35889620",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_orig = raw_data.drop(columns=[\"Attack Type\"])\n",
    "y_orig = raw_data[\"Attack Type\"].astype(\"category\").cat.codes\n",
    "y_test = raw_data[\"Attack Type\"]\n",
    "labels = [\"DDoS\", \"Intrusion\", \"Malware\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea2f4f",
   "metadata": {},
   "source": [
    "# Model found by Merouane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3f5d46",
   "metadata": {},
   "source": [
    "## Pipeline Defition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306cc8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X_orig.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols = X_orig.select_dtypes(include=['object',\"str\"]).columns.tolist()\n",
    "\n",
    "preproc_orig = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "    ]\n",
    ")\n",
    "X_proc = preproc_orig.fit_transform(X_orig)\n",
    "\n",
    "xgb_fs = XGBClassifier(\n",
    "        n_estimators=200, learning_rate=0.05, max_depth=10,\n",
    "        random_state=RANDOM_STATE, tree_method=\"hist\"\n",
    "    )\n",
    "xgb_fs.fit(X_proc, y_orig)\n",
    "importances_orig = xgb_fs.feature_importances_\n",
    "idx_orig = np.argsort(importances_orig)[::-1][:min(800, X_proc.shape[1])]\n",
    "X_sel = X_proc[:, idx_orig]\n",
    "y_sel = y_orig.copy()\n",
    "\n",
    "if hasattr(X_sel, \"toarray\"):\n",
    "    X_sel = X_sel.toarray()\n",
    "\n",
    "sm = SMOTETomek(random_state=RANDOM_STATE)\n",
    "X_sel, y_sel = sm.fit_resample(X_sel, y_sel)\n",
    "y_sel.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57029361",
   "metadata": {},
   "source": [
    "From Smote processing, around 28000 observations are created. Must be comapred to the initial 400000. To keep in mind when we will give smotetomek specific split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba28b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel = PCA(n_components=0.98, svd_solver=\"full\").fit_transform(X_sel)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X_sel, y_sel, test_size=0.2, random_state=RANDOM_STATE, stratify=y_sel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bec6a7",
   "metadata": {},
   "source": [
    "## Model Fitting & Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f2acc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.4497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.44      0.43      0.44      1813\n",
      "   Intrusion       0.46      0.46      0.46      1827\n",
      "     Malware       0.45      0.46      0.45      1835\n",
      "\n",
      "    accuracy                           0.45      5475\n",
      "   macro avg       0.45      0.45      0.45      5475\n",
      "weighted avg       0.45      0.45      0.45      5475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE)\n",
    "model.fit(X_tr, y_tr)\n",
    "pred = model.predict(X_te)\n",
    "accuracy = accuracy_score(y_te, pred)\n",
    "print(f\"Final Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_te, pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c48428",
   "metadata": {},
   "source": [
    "# Model using all features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b856d3f9",
   "metadata": {},
   "source": [
    "There is no features reduction using the xgbclassifier before the smotetomek steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c616d2ca",
   "metadata": {},
   "source": [
    "## Pipeline Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad6e7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 113.32 seconds\n",
      "Final Accuracy: 0.3451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.34      0.33      0.34      2074\n",
      "   Intrusion       0.35      0.36      0.36      2094\n",
      "     Malware       0.35      0.34      0.34      2091\n",
      "\n",
      "    accuracy                           0.35      6259\n",
      "   macro avg       0.35      0.35      0.34      6259\n",
      "weighted avg       0.35      0.35      0.34      6259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preproc_orig = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "    ]\n",
    ")\n",
    "X_proc = preproc_orig.fit_transform(X_orig)\n",
    "\n",
    "X_sel = X_proc.copy()\n",
    "y_sel = y_orig.copy()\n",
    "\n",
    "sm = SMOTETomek(random_state=RANDOM_STATE)\n",
    "X_sel, y_sel = sm.fit_resample(X_sel, y_sel)\n",
    "X_sel = PCA(n_components=200, svd_solver=\"auto\").fit_transform(X_sel)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X_sel, y_sel, test_size=0.2, random_state=RANDOM_STATE, stratify=y_sel\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE)\n",
    "start_time = monotonic()\n",
    "model.fit(X_tr, y_tr)\n",
    "print(f\"Training time: {monotonic() - start_time:.2f} seconds\")\n",
    "pred = model.predict(X_te)\n",
    "accuracy = accuracy_score(y_te, pred)\n",
    "print(f\"Final Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_te, pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b2812a",
   "metadata": {},
   "source": [
    "Need to use xgbclassifier to improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1e031b",
   "metadata": {},
   "source": [
    "# Search of Optimal Hyper-Parameters for the steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca4e6c9",
   "metadata": {},
   "source": [
    "## Pipeline Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555956d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer for XGBoost feature selection\n",
    "class XGBFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=800, random_state=124):\n",
    "        self.n_features = n_features\n",
    "        self.random_state = random_state\n",
    "        self.feature_indices_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Train XGBoost to get feature importances\n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=200, \n",
    "            learning_rate=0.05, \n",
    "            max_depth=10,\n",
    "            random_state=self.random_state, \n",
    "            tree_method=\"hist\"\n",
    "        )\n",
    "        xgb.fit(X, y)\n",
    "        \n",
    "        # Select top N features\n",
    "        importances = xgb.feature_importances_\n",
    "        self.feature_indices_ = np.argsort(importances)[::-1][:min(self.n_features, X.shape[1])]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "    \n",
    "        return X[:, self.feature_indices_]\n",
    "    \n",
    "    def set_fit_request(self, *, y: bool = True):\n",
    "        return self\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_orig, y_orig, test_size=0.2, random_state=RANDOM_STATE, stratify=y_orig\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selector', XGBFeatureSelector(random_state=RANDOM_STATE)),\n",
    "    ('smote', SMOTETomek(random_state=RANDOM_STATE)),\n",
    "    ('pca', PCA(n_components=200, svd_solver=\"auto\")),  # Use integer with auto solver\n",
    "    ('classifier', RandomForestClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'feature_selector__n_features': [400, 800, 1200],\n",
    "    'pca__n_components': [100, 200, 400],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [ 2, 5],\n",
    "    'classifier__max_features': ['sqrt', 'log2']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bbaf4f",
   "metadata": {},
   "source": [
    "## Model Fitting & Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f41cfb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = \"\"\n",
    "while ans.lower() not in [\"y\", \"n\"]:\n",
    "    ans = input(f\"About to run a hyperparameter search. Do you want to proceed? (y/n): \")\n",
    "if ans.lower() == \"y\":\n",
    "\n",
    "    print(\"Starting hyperparameter search with pipeline...\")\n",
    "    print(f\"Testing {len(param_grid['feature_selector__n_features'])} feature counts\")\n",
    "    print(f\"Total combinations: {np.prod([len(v) for v in param_grid.values()])}\")\n",
    "    print(f\"Using n_estimators as resource: [30, 90, 270] trees\")\n",
    "    start_time = monotonic()\n",
    "\n",
    "    halving_cv = HalvingGridSearchCV(\n",
    "        pipeline, \n",
    "        param_grid,\n",
    "        resource='classifier__n_estimators',\n",
    "        min_resources=30,\n",
    "        max_resources=270,\n",
    "        factor=3,\n",
    "        cv=3,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    halving_cv.fit(X_train, y_train)\n",
    "\n",
    "    elapsed = monotonic() - start_time\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Search completed in {elapsed:.2f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Best results\n",
    "    print(f\"\\nüèÜ Best parameters found:\")\n",
    "    for param, value in halving_cv.best_params_.items():\n",
    "        print(f\"   {param}: {value}\")\n",
    "    print(f\"\\nBest CV score: {halving_cv.best_score_:.4f}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    pred = halving_cv.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    print(f\"\\n{classification_report(y_test, pred, target_names=labels)}\")\n",
    "\n",
    "    # Show top 5 configurations\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Top 5 configurations:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    cv_results = pd.DataFrame(halving_cv.cv_results_)\n",
    "    top_5 = cv_results.nlargest(5, 'mean_test_score')[\n",
    "        ['param_feature_selector__n_features', 'param_classifier__n_estimators', \n",
    "        'param_classifier__max_depth', 'mean_test_score', 'rank_test_score']\n",
    "    ]\n",
    "    print(top_5.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2995259",
   "metadata": {},
   "source": [
    "# Model with SmoteTomek and imbalance on outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18048f0a",
   "metadata": {},
   "source": [
    "We defined the output of smotetomek instead of putting it on auto. <br>\n",
    "As we have seen the randomforestclassifier tends to fit more to DDoS attack type, we will create more inputs for the others 2 types <br>\n",
    "The precision was around 88% for DDoS while it was 6% for the ohter 2. So we will over-compensate by that percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9bde68",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp = SimpleImputer(strategy=\"constant\", fill_value=\"unknown\").fit_transform(X_orig[cat_cols])\n",
    "_tmp_ohe = OneHotEncoder(handle_unknown='ignore',drop=\"first\", sparse_output=True).fit(_tmp)\n",
    "all_categories = _tmp_ohe.categories_\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore',drop=\"first\", sparse_output=True, categories=all_categories), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTETomek(random_state=RANDOM_STATE)),\n",
    "    ('classifier', RandomForestClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"smote__sampling_strategy\": [{0: 10000, 1: 20000, 2: 20000},\n",
    "                                 {0: 10000, 1: 30000, 2: 30000},\n",
    "                                 {0: 15000, 1: 15000, 2: 15000},\n",
    "                                 ],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "halving_cv = HalvingGridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid,\n",
    "    resource='classifier__n_estimators',\n",
    "    min_resources=30,\n",
    "    max_resources=270,\n",
    "    factor=3,\n",
    "    cv=3,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=8,\n",
    "    verbose=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a85db0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 30\n",
      "max_resources_: 270\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 18\n",
      "n_resources: 30\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florians/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:261: UserWarning: Found unknown categories in columns [7, 8, 16, 17, 18] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/florians/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:261: UserWarning: Found unknown categories in columns [7, 8, 16, 17, 18] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/florians/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:261: UserWarning: Found unknown categories in columns [7, 8, 16, 17, 18] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/florians/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:261: UserWarning: Found unknown categories in columns [7, 8, 16, 17, 18] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/florians/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:261: UserWarning: Found unknown categories in columns [7, 8, 16, 17, 18] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/florians/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:261: UserWarning: Found unknown categories in columns [7, 8, 16, 17, 18] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/florians/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:261: UserWarning: Found unknown categories in columns [7, 8, 16, 17, 18] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/home/florians/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:261: UserWarning: Found unknown categories in columns [7, 8, 16, 17, 18] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m X_train, X_test, y_train, y_test = train_test_split(X_orig, y_orig, test_size=\u001b[32m0.2\u001b[39m, random_state=RANDOM_STATE, stratify=y_orig)\n\u001b[32m      3\u001b[39m start_time = monotonic()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mhalving_cv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTime taken to fit the model: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m % (monotonic() - start_time))\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest parameters: \u001b[39m\u001b[33m\"\u001b[39m, halving_cv.best_params_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search_successive_halving.py:253\u001b[39m, in \u001b[36mBaseSuccessiveHalving.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28mself\u001b[39m._check_input_parameters(\n\u001b[32m    248\u001b[39m     X=X, y=y, split_params=routed_params.splitter.split\n\u001b[32m    249\u001b[39m )\n\u001b[32m    251\u001b[39m \u001b[38;5;28mself\u001b[39m._n_samples_orig = _num_samples(X)\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[38;5;66;03m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m.best_score_ = \u001b[38;5;28mself\u001b[39m.cv_results_[\u001b[33m\"\u001b[39m\u001b[33mmean_test_score\u001b[39m\u001b[33m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m.best_index_]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1053\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1047\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1048\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1049\u001b[39m     )\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1057\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search_successive_halving.py:357\u001b[39m, in \u001b[36mBaseSuccessiveHalving._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m    350\u001b[39m     cv = \u001b[38;5;28mself\u001b[39m._checked_cv_orig\n\u001b[32m    352\u001b[39m more_results = {\n\u001b[32m    353\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33miter\u001b[39m\u001b[33m\"\u001b[39m: [itr] * n_candidates,\n\u001b[32m    354\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mn_resources\u001b[39m\u001b[33m\"\u001b[39m: [n_resources] * n_candidates,\n\u001b[32m    355\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m results = \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmore_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmore_results\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    361\u001b[39m n_candidates_to_keep = ceil(n_candidates / \u001b[38;5;28mself\u001b[39m.factor)\n\u001b[32m    362\u001b[39m candidate_params = _top_k(results, n_candidates_to_keep, itr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:999\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    992\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    993\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    994\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    995\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    996\u001b[39m         )\n\u001b[32m    997\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m999\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1021\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1022\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:91\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     79\u001b[39m warning_filters = (\n\u001b[32m     80\u001b[39m     filters_func() \u001b[38;5;28;01mif\u001b[39;00m filters_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m warnings.filters\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     84\u001b[39m     (\n\u001b[32m     85\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     90\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_orig, y_orig, test_size=0.2, random_state=RANDOM_STATE, stratify=y_orig)\n",
    "\n",
    "start_time = monotonic()\n",
    "halving_cv.fit(X_train, y_train)\n",
    "print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "print(\"Best parameters: \", halving_cv.best_params_)\n",
    "print(\"Model score: %.3f\" % halving_cv.score(X_test, y_test))\n",
    "y_pred = halving_cv.predict(X_test)\n",
    "print(classification_report(y_pred, y_test, target_names=labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
