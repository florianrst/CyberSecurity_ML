{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8f221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, HalvingGridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import set_config\n",
    "set_config(enable_metadata_routing=True)\n",
    "RANDOM_STATE = 124\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from time import monotonic\n",
    "\n",
    "from utils.data_processing import load_data, raw_columns, full_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1186e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./data\")\n",
    "input_data_path = Path(\"./data/cybersecurity_attacks.csv\")\n",
    "dtypes = {col: col_type for col, col_type in full_dtypes.items() if col in raw_columns}\n",
    "raw_data = load_data(input_data_path)\n",
    "cat_cols = raw_data.select_dtypes(include=[\"category\"]).columns\n",
    "raw_data[cat_cols] = raw_data[cat_cols].astype(\"str\")\n",
    "X_dataset = raw_data.drop(columns=[\"Attack Type\"])\n",
    "Y = raw_data[\"Attack Type\"]\n",
    "X_dataset = X_dataset.fillna(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f84e29e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.519614552999883 Starting transformation\n",
      "2.8568527709999216 Starting transformation\n",
      "3.1367116219998934 Starting transformation\n",
      "3.3412819999998646 Starting transformation\n",
      "3.648516806999851 Starting transformation\n",
      "3.942180014999849 Starting transformation\n",
      "129.0911236490001 Starting transformation\n",
      "131.6338810430002 Starting transformation\n",
      "133.79839264600014 Starting transformation\n",
      "141.8090180600002 Starting transformation\n",
      "144.80258211399996 Starting transformation\n",
      "147.982774737 Starting transformation\n",
      "151.04264689699994 Starting transformation\n",
      "153.93981917400015 Starting transformation\n",
      "156.05417521200025 Starting transformation\n",
      "174.5648307800002 Starting transformation\n",
      "177.41285894300017 Starting transformation\n",
      "179.7568572780001 Starting transformation\n",
      "208.7886488600002 Starting transformation\n",
      "211.21189041800017 Starting transformation\n",
      "213.8293256920001 Starting transformation\n",
      "215.73937395200028 Starting transformation\n",
      "218.20684885799983 Starting transformation\n",
      "220.49343848099988 Starting transformation\n",
      "357.97538394599997 Starting transformation\n",
      "360.95221845900005 Starting transformation\n",
      "363.855764725 Starting transformation\n",
      "377.27529679200006 Starting transformation\n",
      "379.9827095740002 Starting transformation\n",
      "382.03445525200004 Starting transformation\n",
      "396.1211232720002 Starting transformation\n",
      "398.5503069780002 Starting transformation\n",
      "400.41453742800013 Starting transformation\n",
      "403.9864638849999 Starting transformation\n",
      "406.42665888600004 Starting transformation\n",
      "408.63561822600013 Starting transformation\n",
      "503.31996238700003 Starting transformation\n",
      "505.6841308520002 Starting transformation\n",
      "507.9135392920002 Starting transformation\n",
      "519.133881022 Starting transformation\n",
      "521.6374850540001 Starting transformation\n",
      "523.9869054569999 Starting transformation\n",
      "602.7487350450001 Starting transformation\n",
      "604.3684983510002 Starting transformation\n",
      "605.89491782 Starting transformation\n",
      "620.187810034 Starting transformation\n",
      "621.0291857980001 Starting transformation\n",
      "621.7688788559999 Starting transformation\n",
      "622.6565078409999 Starting transformation\n",
      "623.329371627 Starting transformation\n",
      "624.2250812980001 Starting transformation\n",
      "665.882307673 Starting transformation\n",
      "667.8572474900002 Starting transformation\n",
      "669.7790867050003 Starting transformation\n",
      "697.2530341510001 Starting transformation\n",
      "699.741409143 Starting transformation\n",
      "701.922998943 Starting transformation\n",
      "709.8412424379999 Starting transformation\n",
      "711.918729811 Starting transformation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florians/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716.3555096330001 Starting transformation\n",
      "763.3076561490002 Starting transformation\n",
      "765.669410861 Starting transformation\n",
      "767.696000591 Starting transformation\n",
      "767.892301934 Starting transformation\n",
      "770.1479768889999 Starting transformation\n",
      "774.6248297360003 Starting transformation\n",
      "827.7601284530001 Starting transformation\n",
      "831.2919494890002 Starting transformation\n",
      "838.3414600260003 Starting transformation\n",
      "859.6016946610002 Starting transformation\n",
      "862.2200434780002 Starting transformation\n",
      "868.8951738989999 Starting transformation\n",
      "873.7164243299999 Starting transformation\n",
      "876.5045370170001 Starting transformation\n",
      "878.3813250630001 Starting transformation\n",
      "908.4539127110002 Starting transformation\n",
      "912.465156966 Starting transformation\n",
      "915.4428068699999 Starting transformation\n",
      "954.123139537 Starting transformation\n",
      "956.871364049 Starting transformation\n",
      "964.962792029 Starting transformation\n",
      "1127.5952869540001 Starting transformation\n",
      "1130.9611977970003 Starting transformation\n",
      "1134.6731241490002 Starting transformation\n",
      "1164.5020168830001 Starting transformation\n",
      "1167.7642930420002 Starting transformation\n",
      "1170.214089562 Starting transformation\n",
      "1183.493770859 Starting transformation\n",
      "1186.430828766 Starting transformation\n",
      "1188.9081362450002 Starting transformation\n",
      "1189.6307601069998 Starting transformation\n",
      "1192.4837765509997 Starting transformation\n",
      "1195.1128311010002 Starting transformation\n",
      "1208.3388774500004 Starting transformation\n",
      "1210.158864472 Starting transformation\n",
      "1211.9340627630004 Starting transformation\n",
      "1249.1114186729997 Starting transformation\n",
      "1251.2669866 Starting transformation\n",
      "1253.3910876080004 Starting transformation\n",
      "1325.5622807820005 Starting transformation\n",
      "1327.425174175 Starting transformation\n",
      "1328.2168908110002 Starting transformation\n",
      "1330.1221949340002 Starting transformation\n",
      "1331.3427021069997 Starting transformation\n",
      "1333.7194829989999 Starting transformation\n",
      "1334.123641435 Starting transformation\n",
      "1335.9418913269997 Starting transformation\n",
      "1340.0216153369997 Starting transformation\n",
      "1345.3660350349996 Starting transformation\n",
      "1347.3894518749998 Starting transformation\n",
      "1349.4867981399998 Starting transformation\n",
      "1393.312113679 Starting transformation\n",
      "1395.3096491339998 Starting transformation\n",
      "1397.0701670479998 Starting transformation\n",
      "1412.7929436810005 Starting transformation\n",
      "1414.8379816499996 Starting transformation\n",
      "1416.6404327140003 Starting transformation\n",
      "1505.5799900919997 Starting transformation\n",
      "1508.4013802240001 Starting transformation\n",
      "1509.1519853759996 Starting transformation\n",
      "1511.9976862850003 Starting transformation\n",
      "1512.6205726680005 Starting transformation\n",
      "1515.9159850379997 Starting transformation\n",
      "1522.206085589 Starting transformation\n",
      "1526.4054055769998 Starting transformation\n",
      "1675.5616559349996 Starting transformation\n",
      "1678.290915616 Starting transformation\n",
      "1719.3623010120004 Starting transformation\n",
      "1721.583683984 Starting transformation\n",
      "1729.2038564099998 Starting transformation\n",
      "1731.263751301 Starting transformation\n",
      "1785.2070030870004 Starting transformation\n",
      "1787.2297485129998 Starting transformation\n",
      "1800.5186509319997 Starting transformation\n",
      "1802.5642855680003 Starting transformation\n",
      "1805.3794052440003 Starting transformation\n",
      "1805.7939679429996 Starting transformation\n",
      "1806.0893352870003 Starting transformation\n",
      "1806.4379021959999 Starting transformation\n",
      "1806.7034059940001 Starting transformation\n",
      "1807.0639675349998 Starting transformation\n",
      "2106.8878487360003 Starting transformation\n",
      "2109.1084523639997 Starting transformation\n",
      "2111.1487244570003 Starting transformation\n",
      "2114.793676539 Starting transformation\n",
      "2117.049868021 Starting transformation\n",
      "2119.114275368 Starting transformation\n",
      "2120.0623221050005 Starting transformation\n",
      "2122.2289407350004 Starting transformation\n",
      "2124.349700946 Starting transformation\n",
      "2146.88006182 Starting transformation\n",
      "2151.1352824299997 Starting transformation\n",
      "2152.5149497569996 Starting transformation\n",
      "2154.9972983909997 Starting transformation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florians/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2157.6963533209996 Starting transformation\n",
      "2161.55918737 Starting transformation\n",
      "2185.9218017850003 Starting transformation\n",
      "2189.7539994960002 Starting transformation\n",
      "2193.555756507 Starting transformation\n",
      "2524.3477924310005 Starting transformation\n",
      "2526.737784001 Starting transformation\n",
      "2528.935501306 Starting transformation\n",
      "2549.7904752500003 Starting transformation\n",
      "2551.825405735 Starting transformation\n",
      "2553.2884281600004 Starting transformation\n",
      "2553.849695841 Starting transformation\n",
      "2555.3409656480003 Starting transformation\n",
      "2556.5239320530004 Starting transformation\n",
      "2557.4536344040002 Starting transformation\n",
      "2558.8579936359997 Starting transformation\n",
      "2592.315212881 Starting transformation\n",
      "2593.6321974039997 Starting transformation\n",
      "2595.8897550449997 Starting transformation\n",
      "2597.0555065330004 Starting transformation\n",
      "2729.577069015 Starting transformation\n",
      "2730.8003402850004 Starting transformation\n",
      "2747.106359764 Starting transformation\n",
      "2748.264666335 Starting transformation\n",
      "2754.7730076410003 Starting transformation\n",
      "2755.785025367 Starting transformation\n",
      "2757.2522401869996 Starting transformation\n",
      "2757.4246372210005 Starting transformation\n",
      "2757.5977237150005 Starting transformation\n",
      "2757.788959117 Starting transformation\n",
      "2757.999829692 Starting transformation\n",
      "3366.248166594 Starting transformation\n",
      "3367.7798774630005 Starting transformation\n",
      "3371.3644922239996 Starting transformation\n",
      "3373.001189721 Starting transformation\n",
      "3389.004732166 Starting transformation\n",
      "3390.461124162 Starting transformation\n",
      "3390.574535084 Starting transformation\n",
      "3391.9531298140005 Starting transformation\n",
      "3410.6401636940004 Starting transformation\n",
      "3412.013393148 Starting transformation\n",
      "3413.364761524 Starting transformation\n",
      "Time taken to fit the model: 3621.83 seconds\n",
      "3623.04741677 Starting transformation\n",
      "Model score: 0.346\n",
      "3623.6803618159997 Starting transformation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DDoS       0.35      0.34      0.34      2713\n",
      "   Intrusion       0.35      0.35      0.35      2658\n",
      "     Malware       0.34      0.35      0.35      2629\n",
      "\n",
      "    accuracy                           0.35      8000\n",
      "   macro avg       0.35      0.35      0.35      8000\n",
      "weighted avg       0.35      0.35      0.35      8000\n",
      "\n",
      "Best parameters:  {'classifier__n_estimators': 200, 'pca__n_components': 0.95, 'xgbclassifier__n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "num_cols = X_dataset.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols = X_dataset.select_dtypes(include=[\"object\",\"str\"]).columns.tolist()\n",
    "pass_cols = [col for col in X_dataset.columns if col not in cat_cols and col not in num_cols]\n",
    "\n",
    "_tmp = SimpleImputer(strategy=\"constant\", fill_value=\"unknown\").fit_transform(X_dataset[cat_cols])\n",
    "_tmp_ohe = OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\").fit(_tmp)\n",
    "all_categories = _tmp_ohe.categories_\n",
    "\n",
    "param_grid = {\n",
    "    \"xgbclassifier__n_features\": [500, 800, 1000],\n",
    "    \"pca__n_components\": [0.95, 0.98, 0.99],\n",
    "    \"classifier__n_estimators\": [100, 200, 300],\n",
    "}\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "        steps = [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=True, categories=all_categories))\n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", cat_transformer, cat_cols),\n",
    "            (\"num\", numeric_transformer, num_cols)\n",
    "        ])\n",
    "\n",
    "class XGBFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=800, n_estimators=100, learning_rate=0.05, max_depth=10, tree_method=\"hist\", random_state=RANDOM_STATE):\n",
    "        self.n_features = n_features\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.tree_method = tree_method\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        clf = XGBClassifier(\n",
    "            n_estimators=self.n_estimators,\n",
    "            learning_rate=self.learning_rate,\n",
    "            max_depth=self.max_depth,\n",
    "            tree_method=self.tree_method,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        clf.fit(X, y)\n",
    "        importances = clf.feature_importances_\n",
    "        self.selected_idx_ = np.argsort(importances)[::-1][:min(self.n_features, X.shape[1])]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_sel = X[:, self.selected_idx_]\n",
    "        if hasattr(X_sel, \"toarray\"):\n",
    "            X_sel = X_sel.toarray().astype(np.float32)\n",
    "        return X_sel\n",
    "\n",
    "def to_dense(X):\n",
    "    if hasattr(X, \"toarray\"):\n",
    "        return X.toarray().astype(np.float32)\n",
    "    return X.astype(np.float32)\n",
    "\n",
    "class DebugTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.name = name\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        sparse = hasattr(X, \"toarray\")\n",
    "        print(f\"[{self.name}] shape={X.shape}, sparse={sparse}, dtype={X.dtype}\")\n",
    "        return X\n",
    "\n",
    "\n",
    "class TimeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.name = name\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(f\"{monotonic()- start_time} Starting transformation\")\n",
    "        return X\n",
    "\n",
    "\n",
    "pipeline = ImbPipeline(\n",
    "        steps=[\n",
    "            (\"debug0\", TimeTransformer(name=\"Before Preprocessing\")),\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            # (\"debug1\", DebugTransformer(name=\"After Preprocessing\")),\n",
    "            (\"xgbclassifier\", XGBFeatureSelector()),\n",
    "            # (\"debug2\", DebugTransformer(name=\"After XGB Classifier\")),\n",
    "            # (\"densifier\", FunctionTransformer(to_dense)),\n",
    "            # (\"debug3\", DebugTransformer(name=\"After Densifier\")),\n",
    "            (\"syntheticdata\", SMOTETomek(random_state=RANDOM_STATE)),\n",
    "            # (\"debug4\", DebugTransformer(name=\"After SMOTETomek\")),\n",
    "            (\"pca\", PCA(svd_solver=\"full\")),\n",
    "            (\"classifier\", RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE))\n",
    "        ])\n",
    "\n",
    "Yencoder = LabelEncoder()\n",
    "Yencoded = Yencoder.fit_transform(Y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, Yencoded, test_size=0.2, stratify=Yencoded, random_state=RANDOM_STATE)\n",
    "\n",
    "search = HalvingGridSearchCV(pipeline, param_grid, cv=5, factor=3, n_jobs=6, resource=\"xgbclassifier__n_estimators\",\n",
    "                             min_resources=100, max_resources=5000, random_state=RANDOM_STATE)\n",
    "start_time = monotonic()\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "print(\"Model score: %.3f\" % search.score(X_test, y_test))\n",
    "labels = [\"DDoS\", \"Intrusion\", \"Malware\"]\n",
    "y_pred = search.predict(X_test)\n",
    "print(classification_report(y_pred, y_test, target_names=labels))\n",
    "print(\"Best parameters: \", search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
