{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe94b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import TargetEncoder, OneHotEncoder, StandardScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, HalvingGridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn import set_config\n",
    "set_config(enable_metadata_routing=True)\n",
    "\n",
    "from joblib import parallel_backend\n",
    "from time import monotonic\n",
    "from prince import FAMD, MCA\n",
    "\n",
    "from utils.data_processing import load_data, raw_columns, full_dtypes, transform_datetime, df_ua_parser, transform_ipinfo, transform_packetinfo, transform_proxyinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2181af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./data\")\n",
    "if not data_path.joinpath(\"first_ml_processing.csv\").exists():\n",
    "    # Must use clean_data function to load data \n",
    "    input_data_path = Path(\"./data/cybersecurity_attacks.csv\")\n",
    "    dtypes = {col: col_type for col, col_type in full_dtypes.items() if col in raw_columns}\n",
    "    raw_data = load_data(input_data_path, dtype=dtypes)\n",
    "\n",
    "    datetime_columns = [\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\", \"Second\", \"DayOfWeek\", \"IsWeekend\"]\n",
    "    raw_data[datetime_columns] = transform_datetime(raw_data[\"Timestamp\"])\n",
    "    device_columns = [\"String\",\"Browser Name\", \"Browser Version\", \"Browser Minor\", \"Browser Patch\",\n",
    "                    \"Browser Patch Minor\", \"OS Name\", \"OS Version\", \"OS Version Minor\",\n",
    "                    \"OS Version Patch\", \"OS Version Patch Minor\", \"Device Brand\", \"Device Model\",\n",
    "                    \"Device Type\"]\n",
    "    raw_data[device_columns] = df_ua_parser(raw_data[\"Device Information\"])\n",
    "    proxy_columns = [\"Is Proxy\"]\n",
    "    raw_data[proxy_columns] = transform_proxyinfo(raw_data[\"Proxy Information\"])\n",
    "    ip_columns = [\"Int Source IP\", \"Int Destination IP\", \"Global Source IP\", \"Global Destination IP\"]\n",
    "    raw_data[ip_columns] = transform_ipinfo(raw_data[[\"Source IP Address\", \"Destination IP Address\"]])\n",
    "    packet_columns = [\"Packet Bin\"]\n",
    "    raw_data[packet_columns] = transform_packetinfo(raw_data[\"Packet Length\"], scale=False)\n",
    "\n",
    "    processed_data = raw_data.drop(columns=[\"Payload Data\",\"Timestamp\", \"String\", \"Device Information\",\n",
    "                                    \"Proxy Information\", \"Source IP Address\", \"Destination IP Address\"])\n",
    "    processed_data.to_csv(data_path.joinpath(\"first_ml_processing.csv\"), index=False)\n",
    "processed_data = pd.read_csv(data_path.joinpath(\"first_ml_processing.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2655c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true = processed_data[\"Attack Type\"].copy()\n",
    "X_dataset = processed_data.copy().drop(columns=[\"Attack Type\", \"Browser Patch\" , \"Browser Patch Minor\",\n",
    "                                                \"OS Version\", \"OS Version Minor\", \"OS Version Patch\", \"OS Version Patch Minor\",\n",
    "                                                \"Device Type\", \"User Information\", \"Geo-location Data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a5017",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "## PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77724017",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X_dataset.select_dtypes(include=[\"category\",\"str\"]).columns\n",
    "num_cols = X_dataset.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "bool_cols = X_dataset.select_dtypes(include=[\"bool\"]).columns\n",
    "passthrough_columns = [col for col in X_dataset.columns if col not in cat_cols and col not in bool_cols and col not in num_cols]\n",
    "    \n",
    "numeric_transformer = Pipeline(\n",
    "        steps = [(\"scaler\", StandardScaler())]\n",
    "    )\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        (\"encoder\", OrdinalEncoder())\n",
    "        ])\n",
    "boolean_transformer = Pipeline([\n",
    "        (\"encoder\", TargetEncoder(target_type=\"binary\")),\n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", categorical_transformer, cat_cols),\n",
    "            (\"num\", numeric_transformer, num_cols),\n",
    "            (\"bool\", boolean_transformer, bool_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [100, 200],\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_split\": [2, 10, 30],\n",
    "    \"pca__n_components\": [2, 6, 10, 15]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"pca\", PCA(random_state=124)),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=124))\n",
    "        ])\n",
    "\n",
    "relaunch =\"\"\n",
    "while relaunch.lower() not in [\"y\", \"n\"]:\n",
    "    relaunch = input(\"Do you want to relaunch the grid search with raw data? (y/n) \")\n",
    "if relaunch.lower() == \"y\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dataset, Y_true, test_size=0.2, stratify=Y_true, random_state=124)\n",
    "    start_time = monotonic()\n",
    "    gs = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "    print(\"Model score: %.3f\" % gs.score(X_test, y_test))\n",
    "    print(\"Best parameters: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d01108",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X_dataset.select_dtypes(include=[\"category\",\"str\"]).columns\n",
    "num_cols = X_dataset.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "bool_cols = X_dataset.select_dtypes(include=[\"bool\"]).columns\n",
    "passthrough_columns = [col for col in X_dataset.columns if col not in cat_cols and col not in bool_cols and col not in num_cols]\n",
    "    \n",
    "numeric_transformer = Pipeline(\n",
    "        steps = [(\"scaler\", StandardScaler())]\n",
    "    )\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"))\n",
    "        ])\n",
    "boolean_transformer = Pipeline([\n",
    "        (\"encoder\", TargetEncoder(target_type=\"binary\")),\n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", categorical_transformer, cat_cols),\n",
    "            (\"num\", numeric_transformer, num_cols),\n",
    "            (\"bool\", boolean_transformer, bool_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [100, 200],\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_split\": [2, 10, 30],\n",
    "    \"pca__n_components\": [2, 6, 10, 15]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"pca\", PCA(random_state=124)),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=124))\n",
    "        ])\n",
    "\n",
    "relaunch =\"\"\n",
    "while relaunch.lower() not in [\"y\", \"n\"]:\n",
    "    relaunch = input(\"Do you want to relaunch the grid search with an ordinal encoder for categorical data? (y/n) \")\n",
    "if relaunch.lower() == \"y\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dataset, Y_true, test_size=0.2, stratify=Y_true, random_state=124)\n",
    "    start_time = monotonic()\n",
    "    gs = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "    with parallel_backend('threading', n_jobs=2):\n",
    "        gs.fit(X_train, y_train)\n",
    "    print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "    print(\"Model score: %.3f\" % gs.score(X_test, y_test))\n",
    "    print(\"Best parameters: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73fce166",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcat_dataset = X_dataset.copy()\n",
    "columns = [\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\", \"Second\", \"DayOfWeek\", \"Browser Version\", \"Browser Minor\"]\n",
    "Xcat_dataset[columns] = Xcat_dataset[columns].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bda76794",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = Xcat_dataset.select_dtypes(include=[\"category\",\"str\"]).columns\n",
    "num_cols = Xcat_dataset.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "bool_cols = Xcat_dataset.select_dtypes(include=[\"bool\"]).columns\n",
    "passthrough_columns = [col for col in Xcat_dataset.columns if col not in cat_cols and col not in bool_cols and col not in num_cols]\n",
    "    \n",
    "numeric_transformer = Pipeline(\n",
    "        steps = [(\"scaler\", StandardScaler())]\n",
    "    )\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"))\n",
    "        ])\n",
    "boolean_transformer = Pipeline([\n",
    "        (\"encoder\", TargetEncoder(target_type=\"binary\")),\n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", categorical_transformer, cat_cols),\n",
    "            (\"num\", numeric_transformer, num_cols),\n",
    "            (\"bool\", boolean_transformer, bool_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [100, 200],\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_split\": [2, 10, 30],\n",
    "    \"pca__n_components\": [2, 6, 10, 15]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"pca\", PCA(random_state=124)),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=124))\n",
    "        ])\n",
    "relaunch =\"\"\n",
    "while relaunch.lower() not in [\"y\", \"n\"]:\n",
    "    relaunch = input(\"Do you want to relaunch the PCA analysis with more categorical columns? (y/n) \")\n",
    "if relaunch.lower() == \"y\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xcat_dataset, Y_true, test_size=0.2, stratify=Y_true, random_state=124)\n",
    "    start_time = monotonic()\n",
    "    gs = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=2)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "    print(\"Model score: %.3f\" % gs.score(X_test, y_test))\n",
    "    print(\"Best parameters: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490004f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcat_dataset = X_dataset.copy()\n",
    "columns = [\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\", \"Second\", \"DayOfWeek\", \"Browser Version\", \"Browser Minor\",\n",
    "           \"Global Source IP\", \"Global Destination IP\",\"IsWeekend\", \"Is Proxy\", \"Device Brand\", \"Device Model\", \"Browser Name\",\"OS Name\"]\n",
    "Xcat_dataset = Xcat_dataset.drop(columns=columns)\n",
    "bool_cols = Xcat_dataset.select_dtypes(include=[\"bool\"]).columns\n",
    "Xcat_dataset[bool_cols] = Xcat_dataset[bool_cols].astype(\"str\")\n",
    "cat_cols = Xcat_dataset.select_dtypes(include=[\"object\",\"str\"]).columns\n",
    "num_cols = Xcat_dataset.select_dtypes(include=\"number\").columns\n",
    "# Xcat_dataset[cat_cols] = Xcat_dataset[cat_cols].apply(lambda x: x.fillna(\"unknown\"))\n",
    "# numeric_transformer = Pipeline(\n",
    "#         steps = [\n",
    "#             (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "#             (\"scaler\", StandardScaler())\n",
    "#         ])\n",
    "# Xcat_dataset[num_cols] = numeric_transformer.fit_transform(Xcat_dataset[num_cols])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xcat_dataset, Y_true, test_size=0.2, stratify=Y_true, random_state=124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c8fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "passthrough_columns = [col for col in Xcat_dataset.columns if col not in cat_cols and col not in bool_cols and col not in num_cols]\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "        steps = [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", cat_transformer, cat_cols),\n",
    "            (\"num\", numeric_transformer, num_cols)\n",
    "        ]).set_output(transform=\"pandas\")\n",
    "\n",
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [100, 200],\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_split\": [2, 10, 30],\n",
    "    \"famd__n_components\": [2, 6, 10, 15]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"famd\", FAMD()),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=124))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53a45e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florians/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the model: 1392.82 seconds\n",
      "Model score: 0.328\n",
      "Best parameters:  {'classifier__max_depth': 10, 'classifier__min_samples_split': 30, 'classifier__n_estimators': 100, 'famd__n_components': 10}\n"
     ]
    }
   ],
   "source": [
    "relaunch =\"\"\n",
    "while relaunch.lower() not in [\"y\", \"n\"]:\n",
    "    relaunch = input(\"Do you want to relaunch the FAMD analysis? (y/n) \")\n",
    "if relaunch.lower() == \"y\":\n",
    "    start_time = monotonic()\n",
    "    gs = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=2, pre_dispatch=\"n_jobs\")\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "    print(\"Model score: %.3f\" % gs.score(X_test, y_test))\n",
    "    print(\"Best parameters: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_processed = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039f7e60",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m famd = FAMD(n_components=\u001b[32m6\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m xtrain_famd = \u001b[43mfamd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtrain_processed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/prince/utils.py:28\u001b[39m, in \u001b[36mcheck_is_dataframe_input.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, pd.DataFrame):\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     26\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe X argument must be a pandas DataFrame, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(X).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     27\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/prince/pca.py:251\u001b[39m, in \u001b[36mPCA.fit_transform\u001b[39m\u001b[34m(self, X, y, as_array)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"A faster way to fit/transform.\u001b[39;00m\n\u001b[32m    243\u001b[39m \n\u001b[32m    244\u001b[39m \u001b[33;03mThis methods produces exactly the same result as calling `fit(X)` followed\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    248\u001b[39m \n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;28mself\u001b[39m._check_input(X)\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m rc = \u001b[38;5;28mself\u001b[39m.row_coordinates(X)\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rc.to_numpy() \u001b[38;5;28;01mif\u001b[39;00m as_array \u001b[38;5;28;01melse\u001b[39;00m rc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/prince/utils.py:28\u001b[39m, in \u001b[36mcheck_is_dataframe_input.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, pd.DataFrame):\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     26\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe X argument must be a pandas DataFrame, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(X).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     27\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/prince/famd.py:74\u001b[39m, in \u001b[36mFAMD.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m     71\u001b[39m X_cat_oh_norm = X_cat_oh_norm.sparse.to_dense()\n\u001b[32m     73\u001b[39m Z = pd.concat([X_num, X_cat_oh_norm], axis=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Determine column_coordinates_\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# This is based on line 184 in FactoMineR's famd.R file\u001b[39;00m\n\u001b[32m     78\u001b[39m rc = \u001b[38;5;28mself\u001b[39m.row_coordinates(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/prince/utils.py:28\u001b[39m, in \u001b[36mcheck_is_dataframe_input.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, pd.DataFrame):\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     26\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe X argument must be a pandas DataFrame, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(X).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     27\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/prince/pca.py:131\u001b[39m, in \u001b[36mPCA.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, column_weight, supplementary_columns)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m supplementary_columns:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28mself\u001b[39m._column_dist = pd.concat(\n\u001b[32m    122\u001b[39m         (\n\u001b[32m    123\u001b[39m             \u001b[38;5;28mself\u001b[39m._column_dist,\n\u001b[32m   (...)\u001b[39m\u001b[32m    128\u001b[39m         )\n\u001b[32m    129\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28mself\u001b[39m.svd_ = \u001b[43msvd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_svd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_active\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrow_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumn_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumn_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[38;5;28mself\u001b[39m.total_inertia_ = np.sum(\n\u001b[32m    142\u001b[39m     np.square(X_active) * column_weight * sample_weight[:, np.newaxis]\n\u001b[32m    143\u001b[39m )\n\u001b[32m    145\u001b[39m \u001b[38;5;28mself\u001b[39m.column_coordinates_ = pd.DataFrame(\n\u001b[32m    146\u001b[39m     data=\u001b[38;5;28mself\u001b[39m.svd_.V.T * \u001b[38;5;28mself\u001b[39m.eigenvalues_**\u001b[32m0.5\u001b[39m,\n\u001b[32m    147\u001b[39m     index=active_variables,\n\u001b[32m    148\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/prince/svd.py:53\u001b[39m, in \u001b[36mcompute_svd\u001b[39m\u001b[34m(X, n_components, n_iter, engine, random_state, row_weights, column_weights)\u001b[39m\n\u001b[32m     51\u001b[39m     V = V[:n_components, :]\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33msklearn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     U, s, V = \u001b[43mextmath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandomized_svd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mengine has to be one of (\u001b[39m\u001b[33m'\u001b[39m\u001b[33mfbpca\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mscipy\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33msklearn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:542\u001b[39m, in \u001b[36mrandomized_svd\u001b[39m\u001b[34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state, svd_lapack_driver)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m    385\u001b[39m     {\n\u001b[32m    386\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mM\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msparse matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    408\u001b[39m     svd_lapack_driver=\u001b[33m\"\u001b[39m\u001b[33mgesdd\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    409\u001b[39m ):\n\u001b[32m    410\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute a truncated randomized SVD.\u001b[39;00m\n\u001b[32m    411\u001b[39m \n\u001b[32m    412\u001b[39m \u001b[33;03m    This method solves the fixed-rank approximation problem described in [1]_\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    540\u001b[39m \u001b[33;03m    ((3, 2), (2,), (2, 4))\u001b[39;00m\n\u001b[32m    541\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m542\u001b[39m     M = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    543\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _randomized_svd(\n\u001b[32m    544\u001b[39m         M,\n\u001b[32m    545\u001b[39m         n_components=n_components,\n\u001b[32m   (...)\u001b[39m\u001b[32m    552\u001b[39m         svd_lapack_driver=svd_lapack_driver,\n\u001b[32m    553\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1074\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1069\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1070\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1071\u001b[39m     )\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1074\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1082\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1083\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:133\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:182\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    168\u001b[39m     msg_err += (\n\u001b[32m    169\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    180\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "famd = FAMD(n_components=6)\n",
    "xtrain_famd = famd.fit_transform(xtrain_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcat_dataset = X_dataset.copy()\n",
    "columns = [\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\", \"Second\", \"DayOfWeek\", \"Browser Version\", \"Browser Minor\"]\n",
    "Xcat_dataset[columns] = Xcat_dataset[columns].astype(\"str\")\n",
    "bool_cols = Xcat_dataset.select_dtypes(include=[\"bool\"]).columns\n",
    "Xcat_dataset[bool_cols] = Xcat_dataset[bool_cols].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9463bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = Xcat_dataset.select_dtypes(include=[\"category\",\"str\"]).columns\n",
    "num_cols = Xcat_dataset.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "passthrough_columns = [col for col in Xcat_dataset.columns if col not in cat_cols and col not in bool_cols and col not in num_cols]\n",
    "    \n",
    "numeric_transformer = Pipeline(\n",
    "        steps = [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", cat_transformer, cat_cols),\n",
    "            (\"num\", numeric_transformer, num_cols)\n",
    "        ])\n",
    "\n",
    "param_grid = {\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_split\": [2, 10, 30],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=124))\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a6009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "relaunch =\"\"\n",
    "while relaunch.lower() not in [\"y\", \"n\"]:\n",
    "    relaunch = input(\"Do you want to relaunch the HalvingGridSearchCV analysis? (y/n) \")\n",
    "if relaunch.lower() == \"y\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xcat_dataset, Y_true, test_size=0.2, stratify=Y_true, random_state=124)\n",
    "    start_time = monotonic()\n",
    "    gs = HalvingGridSearchCV(pipeline, param_grid, resource = \"classifier__n_estimators\", min_resources=10 , max_resources=500)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "    print(\"Model score: %.3f\" % gs.score(X_test, y_test))\n",
    "    print(\"Best parameters: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451cc801",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Int Source IP\", \"Int Destination IP\", \"Source Port\", \"Destination Port\", \"Protocol\", \"Packet Type\", \"Traffic Type\", \"Attack Signature\"]\n",
    "Xsim_dataset = X_dataset[columns].copy()\n",
    "bool_cols = Xsim_dataset.select_dtypes(include=[\"bool\"]).columns\n",
    "Xsim_dataset[bool_cols] = Xsim_dataset[bool_cols].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e6ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = Xsim_dataset.select_dtypes(include=[\"category\",\"str\"]).columns\n",
    "num_cols = Xsim_dataset.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "passthrough_columns = [col for col in Xsim_dataset.columns if col not in cat_cols and col not in bool_cols and col not in num_cols]\n",
    "    \n",
    "numeric_transformer = Pipeline(\n",
    "        steps = [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", cat_transformer, cat_cols),\n",
    "            (\"num\", numeric_transformer, num_cols)\n",
    "        ])\n",
    "\n",
    "param_grid = {\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_split\": [2, 10, 30],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=124))\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0255be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "relaunch =\"\"\n",
    "while relaunch.lower() not in [\"y\", \"n\"]:\n",
    "    relaunch = input(\"Do you want to relaunch the simple HalvingGridSearchCV analysis? (y/n) \")\n",
    "if relaunch.lower() == \"y\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xsim_dataset, Y_true, test_size=0.2, stratify=Y_true, random_state=124)\n",
    "    start_time = monotonic()\n",
    "    gs = HalvingGridSearchCV(pipeline, param_grid, resource = \"classifier__n_estimators\", min_resources=10 , max_resources=1000, factor=2)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "    print(\"Model score: %.3f\" % gs.score(X_test, y_test))\n",
    "    print(\"Best parameters: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8712388",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Source Port\", \"Destination Port\", \"Protocol\", \"Packet Type\", \"Traffic Type\", \"Attack Signature\", \"Network Segment\"]\n",
    "Xsim_dataset = X_dataset[columns].copy()\n",
    "bool_cols = Xsim_dataset.select_dtypes(include=[\"bool\"]).columns\n",
    "Xsim_dataset[bool_cols] = Xsim_dataset[bool_cols].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1243357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = Xsim_dataset.select_dtypes(include=[\"category\",\"str\"]).columns\n",
    "num_cols = Xsim_dataset.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "passthrough_columns = [col for col in Xsim_dataset.columns if col not in cat_cols and col not in bool_cols and col not in num_cols]\n",
    "    \n",
    "numeric_transformer = Pipeline(\n",
    "        steps = [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", cat_transformer, cat_cols),\n",
    "            (\"num\", numeric_transformer, num_cols)\n",
    "        ])\n",
    "\n",
    "param_grid = {\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_split\": [2, 10, 30],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=124))\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc08f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "relaunch =\"\"\n",
    "while relaunch.lower() not in [\"y\", \"n\"]:\n",
    "    relaunch = input(\"Do you want to relaunch the simple HalvingGridSearchCV analysis? (y/n) \")\n",
    "if relaunch.lower() == \"y\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xsim_dataset, Y_true, test_size=0.2, stratify=Y_true, random_state=124)\n",
    "    start_time = monotonic()\n",
    "    gs = HalvingGridSearchCV(pipeline, param_grid, resource = \"classifier__n_estimators\", min_resources=10 , max_resources=500)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "    print(\"Model score: %.3f\" % gs.score(X_test, y_test))\n",
    "    print(\"Best parameters: \", gs.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
