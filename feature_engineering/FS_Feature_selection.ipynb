{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe94b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import TargetEncoder, OneHotEncoder, StandardScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, HalvingGridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn import set_config\n",
    "set_config(enable_metadata_routing=True)\n",
    "\n",
    "from joblib import parallel_backend\n",
    "from time import monotonic\n",
    "from prince import FAMD\n",
    "\n",
    "from utils.data_processing import load_data, raw_columns, full_dtypes, transform_datetime, df_ua_parser, transform_ipinfo, transform_packetinfo, transform_proxyinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2181af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./data\")\n",
    "if not data_path.joinpath(\"first_ml_processing.csv\").exists():\n",
    "    # Must use clean_data function to load data \n",
    "    input_data_path = Path(\"./data/cybersecurity_attacks.csv\")\n",
    "    dtypes = {col: col_type for col, col_type in full_dtypes.items() if col in raw_columns}\n",
    "    raw_data = load_data(input_data_path, dtype=dtypes)\n",
    "\n",
    "    datetime_columns = [\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\", \"Second\", \"DayOfWeek\", \"IsWeekend\"]\n",
    "    raw_data[datetime_columns] = transform_datetime(raw_data[\"Timestamp\"])\n",
    "    device_columns = [\"String\",\"Browser Name\", \"Browser Version\", \"Browser Minor\", \"Browser Patch\",\n",
    "                    \"Browser Patch Minor\", \"OS Name\", \"OS Version\", \"OS Version Minor\",\n",
    "                    \"OS Version Patch\", \"OS Version Patch Minor\", \"Device Brand\", \"Device Model\",\n",
    "                    \"Device Type\"]\n",
    "    raw_data[device_columns] = df_ua_parser(raw_data[\"Device Information\"])\n",
    "    proxy_columns = [\"Is Proxy\"]\n",
    "    raw_data[proxy_columns] = transform_proxyinfo(raw_data[\"Proxy Information\"])\n",
    "    ip_columns = [\"Int Source IP\", \"Int Destination IP\", \"Global Source IP\", \"Global Destination IP\"]\n",
    "    raw_data[ip_columns] = transform_ipinfo(raw_data[[\"Source IP Address\", \"Destination IP Address\"]])\n",
    "    packet_columns = [\"Packet Bin\"]\n",
    "    raw_data[packet_columns] = transform_packetinfo(raw_data[\"Packet Length\"], scale=False)\n",
    "\n",
    "    processed_data = raw_data.drop(columns=[\"Payload Data\",\"Timestamp\", \"String\", \"Device Information\",\n",
    "                                    \"Proxy Information\", \"Source IP Address\", \"Destination IP Address\"])\n",
    "    processed_data.to_csv(data_path.joinpath(\"first_ml_processing.csv\"), index=False)\n",
    "processed_data = pd.read_csv(data_path.joinpath(\"first_ml_processing.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2655c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true = processed_data[\"Attack Type\"].copy()\n",
    "X_dataset = processed_data.copy().drop(columns=[\"Attack Type\", \"Browser Patch\" , \"Browser Patch Minor\",\n",
    "                                                \"OS Version\", \"OS Version Minor\", \"OS Version Patch\", \"OS Version Patch Minor\",\n",
    "                                                \"Device Type\", \"User Information\", \"Geo-location Data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a5017",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "## PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77724017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the model: 3813.31 seconds\n",
      "Model score: 0.330\n",
      "Best parameters:  {'classifier__max_depth': 10, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 200, 'pca__n_components': 10}\n"
     ]
    }
   ],
   "source": [
    "cat_cols = X_dataset.select_dtypes(include=[\"category\",\"str\"]).columns\n",
    "num_cols = X_dataset.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "bool_cols = X_dataset.select_dtypes(include=[\"bool\"]).columns\n",
    "passthrough_columns = [col for col in X_dataset.columns if col not in cat_cols and col not in bool_cols and col not in num_cols]\n",
    "    \n",
    "numeric_transformer = Pipeline(\n",
    "        steps = [(\"scaler\", StandardScaler())]\n",
    "    )\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        (\"encoder\", OrdinalEncoder())\n",
    "        ])\n",
    "boolean_transformer = Pipeline([\n",
    "        (\"encoder\", TargetEncoder(target_type=\"binary\")),\n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", categorical_transformer, cat_cols),\n",
    "            (\"num\", numeric_transformer, num_cols),\n",
    "            (\"bool\", boolean_transformer, bool_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [100, 200],\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_split\": [2, 10, 30],\n",
    "    \"pca__n_components\": [2, 6, 10, 15]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"pca\", PCA(random_state=124)),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=124))\n",
    "        ])\n",
    "\n",
    "relaunch =\"\"\n",
    "while relaunch.lower() not in [\"y\", \"n\"]:\n",
    "    relaunch = input(\"Do you want to relaunch the grid search with raw data? (y/n) \")\n",
    "if relaunch.lower() == \"y\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dataset, Y_true, test_size=0.2, stratify=Y_true, random_state=124)\n",
    "    start_time = monotonic()\n",
    "    gs = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "    print(\"Model score: %.3f\" % gs.score(X_test, y_test))\n",
    "    print(\"Best parameters: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d01108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the model: 2063.10 seconds\n",
      "Model score: 0.327\n",
      "Best parameters:  {'classifier__max_depth': None, 'classifier__min_samples_split': 30, 'classifier__n_estimators': 100, 'pca__n_components': 2}\n"
     ]
    }
   ],
   "source": [
    "cat_cols = X_dataset.select_dtypes(include=[\"category\",\"str\"]).columns\n",
    "num_cols = X_dataset.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "bool_cols = X_dataset.select_dtypes(include=[\"bool\"]).columns\n",
    "passthrough_columns = [col for col in X_dataset.columns if col not in cat_cols and col not in bool_cols and col not in num_cols]\n",
    "    \n",
    "numeric_transformer = Pipeline(\n",
    "        steps = [(\"scaler\", StandardScaler())]\n",
    "    )\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"))\n",
    "        ])\n",
    "boolean_transformer = Pipeline([\n",
    "        (\"encoder\", TargetEncoder(target_type=\"binary\")),\n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", categorical_transformer, cat_cols),\n",
    "            (\"num\", numeric_transformer, num_cols),\n",
    "            (\"bool\", boolean_transformer, bool_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [100, 200],\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_split\": [2, 10, 30],\n",
    "    \"pca__n_components\": [2, 6, 10, 15]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"pca\", PCA(random_state=124)),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=124))\n",
    "        ])\n",
    "\n",
    "relaunch =\"\"\n",
    "while relaunch.lower() not in [\"y\", \"n\"]:\n",
    "    relaunch = input(\"Do you want to relaunch the grid search with an ordinal encoder for categorical data? (y/n) \")\n",
    "if relaunch.lower() == \"y\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dataset, Y_true, test_size=0.2, stratify=Y_true, random_state=124)\n",
    "    start_time = monotonic()\n",
    "    gs = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "    with parallel_backend('threading', n_jobs=2):\n",
    "        gs.fit(X_train, y_train)\n",
    "    print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "    print(\"Model score: %.3f\" % gs.score(X_test, y_test))\n",
    "    print(\"Best parameters: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73fce166",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcat_dataset = X_dataset.copy()\n",
    "columns = [\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\", \"Second\", \"DayOfWeek\", \"Browser Version\", \"Browser Minor\"]\n",
    "Xcat_dataset[columns] = Xcat_dataset[columns].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bda76794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florians/Cours/CyberSecurity_ML/.venv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the model: 2098.98 seconds\n",
      "Model score: 0.340\n",
      "Best parameters:  {'classifier__max_depth': 20, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 100, 'pca__n_components': 15}\n"
     ]
    }
   ],
   "source": [
    "cat_cols = Xcat_dataset.select_dtypes(include=[\"category\",\"str\"]).columns\n",
    "num_cols = Xcat_dataset.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "bool_cols = Xcat_dataset.select_dtypes(include=[\"bool\"]).columns\n",
    "passthrough_columns = [col for col in Xcat_dataset.columns if col not in cat_cols and col not in bool_cols and col not in num_cols]\n",
    "    \n",
    "numeric_transformer = Pipeline(\n",
    "        steps = [(\"scaler\", StandardScaler())]\n",
    "    )\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"))\n",
    "        ])\n",
    "boolean_transformer = Pipeline([\n",
    "        (\"encoder\", TargetEncoder(target_type=\"binary\")),\n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", categorical_transformer, cat_cols),\n",
    "            (\"num\", numeric_transformer, num_cols),\n",
    "            (\"bool\", boolean_transformer, bool_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [100, 200],\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_split\": [2, 10, 30],\n",
    "    \"pca__n_components\": [2, 6, 10, 15]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"pca\", PCA(random_state=124)),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=124))\n",
    "        ])\n",
    "relaunch =\"\"\n",
    "while relaunch.lower() not in [\"y\", \"n\"]:\n",
    "    relaunch = input(\"Do you want to relaunch the PCA analysis with more categorical columns? (y/n) \")\n",
    "if relaunch.lower() == \"y\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xcat_dataset, Y_true, test_size=0.2, stratify=Y_true, random_state=124)\n",
    "    start_time = monotonic()\n",
    "    gs = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=2)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "    print(\"Model score: %.3f\" % gs.score(X_test, y_test))\n",
    "    print(\"Best parameters: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490004f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcat_dataset = X_dataset.copy()\n",
    "columns = [\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\", \"Second\", \"DayOfWeek\", \"Browser Version\", \"Browser Minor\"]\n",
    "Xcat_dataset[columns] = Xcat_dataset[columns].astype(\"str\")\n",
    "bool_cols = Xcat_dataset.select_dtypes(include=[\"bool\"]).columns\n",
    "Xcat_dataset[bool_cols] = Xcat_dataset[bool_cols].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = Xcat_dataset.select_dtypes(include=[\"category\",\"str\"]).columns\n",
    "num_cols = Xcat_dataset.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "passthrough_columns = [col for col in Xcat_dataset.columns if col not in cat_cols and col not in bool_cols and col not in num_cols]\n",
    "    \n",
    "numeric_transformer = Pipeline(\n",
    "        steps = [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", cat_transformer, cat_cols),\n",
    "            (\"num\", numeric_transformer, num_cols)\n",
    "        ]).set_output(transform=\"pandas\")\n",
    "\n",
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [100, 200],\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_split\": [2, 10, 30],\n",
    "    \"famd__n_components\": [2, 6, 10, 15]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"famd\", FAMD()),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=124))\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a45e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "relaunch =\"\"\n",
    "while relaunch.lower() not in [\"y\", \"n\"]:\n",
    "    relaunch = input(\"Do you want to relaunch the FAMD analysis? (y/n) \")\n",
    "if relaunch.lower() == \"y\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xcat_dataset, Y_true, test_size=0.2, stratify=Y_true, random_state=124)\n",
    "    start_time = monotonic()\n",
    "    gs = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=2, pre_dispatch=\"n_jobs\")\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "    print(\"Model score: %.3f\" % gs.score(X_test, y_test))\n",
    "    print(\"Best parameters: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_processed = preprocessor.fit_transform(Xcat_dataset, Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcat_dataset = X_dataset.copy()\n",
    "columns = [\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\", \"Second\", \"DayOfWeek\", \"Browser Version\", \"Browser Minor\"]\n",
    "Xcat_dataset[columns] = Xcat_dataset[columns].astype(\"str\")\n",
    "bool_cols = Xcat_dataset.select_dtypes(include=[\"bool\"]).columns\n",
    "Xcat_dataset[bool_cols] = Xcat_dataset[bool_cols].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9463bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = Xcat_dataset.select_dtypes(include=[\"category\",\"str\"]).columns\n",
    "num_cols = Xcat_dataset.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "passthrough_columns = [col for col in Xcat_dataset.columns if col not in cat_cols and col not in bool_cols and col not in num_cols]\n",
    "    \n",
    "numeric_transformer = Pipeline(\n",
    "        steps = [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", cat_transformer, cat_cols),\n",
    "            (\"num\", numeric_transformer, num_cols)\n",
    "        ])\n",
    "\n",
    "param_grid = {\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_split\": [2, 10, 30],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=124))\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a6009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "relaunch =\"\"\n",
    "while relaunch.lower() not in [\"y\", \"n\"]:\n",
    "    relaunch = input(\"Do you want to relaunch the HalvingGridSearchCV analysis? (y/n) \")\n",
    "if relaunch.lower() == \"y\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xcat_dataset, Y_true, test_size=0.2, stratify=Y_true, random_state=124)\n",
    "    start_time = monotonic()\n",
    "    gs = HalvingGridSearchCV(pipeline, param_grid, resource = \"classifier__n_estimators\", min_resources=10 , max_resources=500)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "    print(\"Model score: %.3f\" % gs.score(X_test, y_test))\n",
    "    print(\"Best parameters: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451cc801",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Int Source IP\", \"Int Destination IP\", \"Source Port\", \"Destination Port\", \"Protocol\", \"Packet Type\", \"Traffic Type\", \"Attack Signature\"]\n",
    "Xsim_dataset = X_dataset[columns].copy()\n",
    "bool_cols = Xsim_dataset.select_dtypes(include=[\"bool\"]).columns\n",
    "Xsim_dataset[bool_cols] = Xsim_dataset[bool_cols].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e6ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = Xsim_dataset.select_dtypes(include=[\"category\",\"str\"]).columns\n",
    "num_cols = Xsim_dataset.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "passthrough_columns = [col for col in Xsim_dataset.columns if col not in cat_cols and col not in bool_cols and col not in num_cols]\n",
    "    \n",
    "numeric_transformer = Pipeline(\n",
    "        steps = [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", cat_transformer, cat_cols),\n",
    "            (\"num\", numeric_transformer, num_cols)\n",
    "        ])\n",
    "\n",
    "param_grid = {\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_split\": [2, 10, 30],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=124))\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0255be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "relaunch =\"\"\n",
    "while relaunch.lower() not in [\"y\", \"n\"]:\n",
    "    relaunch = input(\"Do you want to relaunch the simple HalvingGridSearchCV analysis? (y/n) \")\n",
    "if relaunch.lower() == \"y\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xsim_dataset, Y_true, test_size=0.2, stratify=Y_true, random_state=124)\n",
    "    start_time = monotonic()\n",
    "    gs = HalvingGridSearchCV(pipeline, param_grid, resource = \"classifier__n_estimators\", min_resources=10 , max_resources=1000, factor=2)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "    print(\"Model score: %.3f\" % gs.score(X_test, y_test))\n",
    "    print(\"Best parameters: \", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8712388",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Source Port\", \"Destination Port\", \"Protocol\", \"Packet Type\", \"Traffic Type\", \"Attack Signature\", \"Network Segment\"]\n",
    "Xsim_dataset = X_dataset[columns].copy()\n",
    "bool_cols = Xsim_dataset.select_dtypes(include=[\"bool\"]).columns\n",
    "Xsim_dataset[bool_cols] = Xsim_dataset[bool_cols].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1243357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = Xsim_dataset.select_dtypes(include=[\"category\",\"str\"]).columns\n",
    "num_cols = Xsim_dataset.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "passthrough_columns = [col for col in Xsim_dataset.columns if col not in cat_cols and col not in bool_cols and col not in num_cols]\n",
    "    \n",
    "numeric_transformer = Pipeline(\n",
    "        steps = [\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", cat_transformer, cat_cols),\n",
    "            (\"num\", numeric_transformer, num_cols)\n",
    "        ])\n",
    "\n",
    "param_grid = {\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_split\": [2, 10, 30],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=124))\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc08f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "relaunch =\"\"\n",
    "while relaunch.lower() not in [\"y\", \"n\"]:\n",
    "    relaunch = input(\"Do you want to relaunch the simple HalvingGridSearchCV analysis? (y/n) \")\n",
    "if relaunch.lower() == \"y\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xsim_dataset, Y_true, test_size=0.2, stratify=Y_true, random_state=124)\n",
    "    start_time = monotonic()\n",
    "    gs = HalvingGridSearchCV(pipeline, param_grid, resource = \"classifier__n_estimators\", min_resources=10 , max_resources=500)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(\"Time taken to fit the model: %.2f seconds\" % (monotonic() - start_time))\n",
    "    print(\"Model score: %.3f\" % gs.score(X_test, y_test))\n",
    "    print(\"Best parameters: \", gs.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
